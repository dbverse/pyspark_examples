{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/07 09:23:14 WARN Utils: Your hostname, WDSCBELT456 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/07 09:23:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 09:23:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SampleSparkCode\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Dinesh| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [Row(\"Dinesh\",\"34\")]\n",
    "cols = ['Name','Age']\n",
    "df_test = spark.createDataFrame(data,schema=cols)\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Dinesh| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from {df}\",df=df_test).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "|AddressID|       AddressLine1|AddressLine2|    City|StateProvince|CountryRegion|PostalCode|             rowguid|        ModifiedDate|\n",
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "|        9|  8713 Yosemite Ct.|        NULL| Bothell|   Washington|United States|     98011|268af621-76d7-4c7...|2006-07-01 00:00:...|\n",
      "|       11|1318 Lasalle Street|        NULL| Bothell|   Washington|United States|     98011|981b3303-aca2-49c...|2007-04-01 00:00:...|\n",
      "|       25|   9178 Jumping St.|        NULL|  Dallas|        Texas|United States|     75201|c8df3bd9-48f0-465...|2006-09-01 00:00:...|\n",
      "|       28|   9228 Via Del Sol|        NULL| Phoenix|      Arizona|United States|     85004|12ae5ee1-fc3e-468...|2005-09-01 00:00:...|\n",
      "|       32|  26910 Indela Road|        NULL|Montreal|       Quebec|       Canada|   H1Y 2H5|84a95f62-3ae8-4e7...|2006-08-01 00:00:...|\n",
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_address = spark.read.csv(\"..\\data\\Address.csv\",header=True)\n",
    "df_address.show(5)\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|count(1)|            City|\n",
      "+--------+----------------+\n",
      "|       1|      Pnot-Rouge|\n",
      "|       1|     Springfield|\n",
      "|       1| North Las Vegas|\n",
      "|       1|          Auburn|\n",
      "|       4|         Phoenix|\n",
      "|       2|        Winnipeg|\n",
      "|       1|   Lake Elsinore|\n",
      "|       1|       Bountiful|\n",
      "|       2|       Clackamas|\n",
      "|       1|          Monroe|\n",
      "|       1|        Westland|\n",
      "|       2|     Culver City|\n",
      "|       1|         Hanford|\n",
      "|       4|         Bothell|\n",
      "|       3|         Everett|\n",
      "|       6|          Ottawa|\n",
      "|       1|North Sioux City|\n",
      "|       1|        Lewiston|\n",
      "|       6|          Dallas|\n",
      "|       1|     Great Falls|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*), City from {df} group by City\",df=df_address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address = spark.read.csv(\"..\\data\\Address.csv\",header=True)\n",
    "df_customer = spark.read.csv(\"..\\data\\Customer.csv\",header=True)\n",
    "df_customer_address = spark.read.csv(\"..\\data\\CustomerAddress.csv\",header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_customer_address = df_customer.join(df_customer_address,df_customer.CustomerID==df_customer_address.CustomerID) \\\n",
    "                                    .join(df_address,df_customer_address.AddressID==df_address.AddressID)\n",
    "df_dim_customer_address.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|Address_Count|   StateProvince|\n",
      "+-------------+----------------+\n",
      "|            9|            Utah|\n",
      "|            1|        Manitoba|\n",
      "|            1|       Brunswick|\n",
      "|            7|       Minnesota|\n",
      "|           17|          Oregon|\n",
      "|           37|           Texas|\n",
      "|           13|         Alberta|\n",
      "|            7|          Nevada|\n",
      "|           48|      Washington|\n",
      "|           14|        Illinois|\n",
      "|            3|      New Mexico|\n",
      "|           11|        Missouri|\n",
      "|           51|         Ontario|\n",
      "|            3|         Montana|\n",
      "|           16|        Michigan|\n",
      "|           17|British Columbia|\n",
      "|            4|         Wyoming|\n",
      "|           24|          Quebec|\n",
      "|           13|         Arizona|\n",
      "|           38|         England|\n",
      "+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as Address_Count, StateProvince from {df} group by StateProvince\",df=df_dim_customer_address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data = [\n",
    "    {'id': 1, 'name': 'Bob', 'department': 'Marketing', 'salary': 9104,\n",
    "     'hire_date': '2018-12-29', 'ssn': '848-97-2099', 'performance_score': 3.6,\n",
    "     'incentive_percent': 14.0, 'grade': 'D', 'grade_start_date': '2019-06-13',\n",
    "     'grade_end_date': '2021-03-05'},\n",
    "\n",
    "    {'id': 1, 'name': 'Bob', 'department': 'Marketing', 'salary': 9104,\n",
    "     'hire_date': '2018-12-29', 'ssn': '848-97-2099', 'performance_score': 3.6,\n",
    "     'incentive_percent': 14.0, 'grade': 'C', 'grade_start_date': '2019-03-28',\n",
    "     'grade_end_date': '2020-08-12'},\n",
    "\n",
    "    {'id': 2, 'name': 'Eve', 'department': 'HR', 'salary': 11405,\n",
    "     'hire_date': '2019-09-16', 'ssn': '374-89-8340', 'performance_score': 4.8,\n",
    "     'incentive_percent': None, 'grade': 'C', 'grade_start_date': '2019-11-23',\n",
    "     'grade_end_date': '2021-02-13'},\n",
    "\n",
    "    {'id': 3, 'name': 'Grace', 'department': 'Finance', 'salary': 8176,\n",
    "     'hire_date': '2017-01-03', 'ssn': '850-34-8593', 'performance_score': 4.8,\n",
    "     'incentive_percent': 15.1, 'grade': 'C', 'grade_start_date': '2017-05-29',\n",
    "     'grade_end_date': '2019-04-12'},\n",
    "\n",
    "    {'id': 4, 'name': 'Charlie', 'department': 'Marketing', 'salary': 5543,\n",
    "     'hire_date': '2017-12-28', 'ssn': '471-89-7669', 'performance_score': 3.4,\n",
    "     'incentive_percent': None, 'grade': 'C', 'grade_start_date': '2018-04-12',\n",
    "     'grade_end_date': '2020-02-21'},\n",
    "\n",
    "    {'id': 5, 'name': 'Grace', 'department': 'IT', 'salary': 11013,\n",
    "     'hire_date': '2015-07-03', 'ssn': '950-10-4559', 'performance_score': None,\n",
    "     'incentive_percent': 11.9, 'grade': 'D', 'grade_start_date': '2015-12-17',\n",
    "     'grade_end_date': '2017-09-15'},\n",
    "\n",
    "    {'id': 6, 'name': 'Eve', 'department': 'HR', 'salary': 7755,\n",
    "     'hire_date': '2016-07-18', 'ssn': '653-29-5109', 'performance_score': None,\n",
    "     'incentive_percent': 5.7, 'grade': 'A', 'grade_start_date': '2016-09-24',\n",
    "     'grade_end_date': '2018-07-01'},\n",
    "\n",
    "    {'id': 7, 'name': 'Bob', 'department': 'Sales', 'salary': 10888,\n",
    "     'hire_date': '2016-06-16', 'ssn': '549-14-5445', 'performance_score': 3.9,\n",
    "     'incentive_percent': 14.3, 'grade': 'A', 'grade_start_date': '2016-08-04',\n",
    "     'grade_end_date': '2017-11-17'},\n",
    "\n",
    "    {'id': 8, 'name': 'Alice', 'department': 'Finance', 'salary': 11532,\n",
    "     'hire_date': '2015-02-01', 'ssn': '428-18-3432', 'performance_score': None,\n",
    "     'incentive_percent': 19.0, 'grade': 'B', 'grade_start_date': '2015-07-27',\n",
    "     'grade_end_date': '2017-02-17'},\n",
    "\n",
    "    {'id': 9, 'name': 'Alice', 'department': 'Marketing', 'salary': 11169,\n",
    "     'hire_date': '2018-02-28', 'ssn': '621-46-2389', 'performance_score': None,\n",
    "     'incentive_percent': 11.8, 'grade': 'B', 'grade_start_date': '2018-06-26',\n",
    "     'grade_end_date': '2019-08-22'},\n",
    "\n",
    "    {'id': 10, 'name': 'Eve', 'department': 'Marketing', 'salary': 10591,\n",
    "     'hire_date': '2017-12-15', 'ssn': '710-34-8871', 'performance_score': None,\n",
    "     'incentive_percent': 7.1, 'grade': 'B', 'grade_start_date': '2018-05-21',\n",
    "     'grade_end_date': '2019-07-19'},\n",
    "\n",
    "    {'id': 11, 'name': 'Grace', 'department': 'Sales', 'salary': 7566,\n",
    "     'hire_date': '2019-11-24', 'ssn': '685-73-7275', 'performance_score': None,\n",
    "     'incentive_percent': None, 'grade': 'D', 'grade_start_date': '2020-01-10',\n",
    "     'grade_end_date': '2020-09-20'},\n",
    "\n",
    "    {'id': 12, 'name': 'Eve', 'department': 'IT', 'salary': 4874,\n",
    "     'hire_date': '2016-02-16', 'ssn': '602-70-5971', 'performance_score': None,\n",
    "     'incentive_percent': None, 'grade': 'B', 'grade_start_date': '2016-04-22',\n",
    "     'grade_end_date': '2017-01-13'},\n",
    "\n",
    "    {'id': 13, 'name': 'Bob', 'department': 'Finance', 'salary': 6067,\n",
    "     'hire_date': '2015-02-18', 'ssn': '965-10-2064', 'performance_score': 2.8,\n",
    "     'incentive_percent': 8.7, 'grade': 'E', 'grade_start_date': '2015-04-08',\n",
    "     'grade_end_date': '2015-10-06'},\n",
    "\n",
    "    {'id': 14, 'name': 'Eve', 'department': 'IT', 'salary': 10012,\n",
    "     'hire_date': '2015-11-24', 'ssn': '479-14-9198', 'performance_score': None,\n",
    "     'incentive_percent': 11.8, 'grade': 'E', 'grade_start_date': '2016-05-07',\n",
    "     'grade_end_date': '2017-01-08'}\n",
    "]\n",
    "column_names = [\n",
    "    \"id\", \"name\", \"department\", \"salary\", \"hire_date\", \"ssn\", \n",
    "    \"performance_score\", \"incentive_percent\", \"grade\", \n",
    "    \"grade_start_date\", \"grade_end_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(employee_data).select(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "|id |name   |department|salary|hire_date |ssn        |performance_score|incentive_percent|grade|grade_start_date|grade_end_date|\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "|1  |Bob    |Marketing |9104  |2018-12-29|848-97-2099|3.6              |14.0             |D    |2019-06-13      |2021-03-05    |\n",
      "|1  |Bob    |Marketing |9104  |2018-12-29|848-97-2099|3.6              |14.0             |C    |2019-03-28      |2020-08-12    |\n",
      "|2  |Eve    |HR        |11405 |2019-09-16|374-89-8340|4.8              |NULL             |C    |2019-11-23      |2021-02-13    |\n",
      "|3  |Grace  |Finance   |8176  |2017-01-03|850-34-8593|4.8              |15.1             |C    |2017-05-29      |2019-04-12    |\n",
      "|4  |Charlie|Marketing |5543  |2017-12-28|471-89-7669|3.4              |NULL             |C    |2018-04-12      |2020-02-21    |\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
