{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SampleSparkCode\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Dinesh| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [Row(\"Dinesh\",\"34\")]\n",
    "cols = ['Name','Age']\n",
    "df_test = spark.createDataFrame(data,schema=cols)\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Dinesh| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from {df}\",df=df_test).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "|AddressID|       AddressLine1|AddressLine2|    City|StateProvince|CountryRegion|PostalCode|             rowguid|        ModifiedDate|\n",
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "|        9|  8713 Yosemite Ct.|        NULL| Bothell|   Washington|United States|     98011|268af621-76d7-4c7...|2006-07-01 00:00:...|\n",
      "|       11|1318 Lasalle Street|        NULL| Bothell|   Washington|United States|     98011|981b3303-aca2-49c...|2007-04-01 00:00:...|\n",
      "|       25|   9178 Jumping St.|        NULL|  Dallas|        Texas|United States|     75201|c8df3bd9-48f0-465...|2006-09-01 00:00:...|\n",
      "|       28|   9228 Via Del Sol|        NULL| Phoenix|      Arizona|United States|     85004|12ae5ee1-fc3e-468...|2005-09-01 00:00:...|\n",
      "|       32|  26910 Indela Road|        NULL|Montreal|       Quebec|       Canada|   H1Y 2H5|84a95f62-3ae8-4e7...|2006-08-01 00:00:...|\n",
      "+---------+-------------------+------------+--------+-------------+-------------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_address = spark.read.csv(\"..\\data\\Address.csv\",header=True)\n",
    "df_address.show(5)\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|count(1)|            City|\n",
      "+--------+----------------+\n",
      "|       1|      Pnot-Rouge|\n",
      "|       1|     Springfield|\n",
      "|       1| North Las Vegas|\n",
      "|       1|          Auburn|\n",
      "|       4|         Phoenix|\n",
      "|       2|        Winnipeg|\n",
      "|       1|   Lake Elsinore|\n",
      "|       1|       Bountiful|\n",
      "|       2|       Clackamas|\n",
      "|       1|          Monroe|\n",
      "|       1|        Westland|\n",
      "|       2|     Culver City|\n",
      "|       1|         Hanford|\n",
      "|       4|         Bothell|\n",
      "|       3|         Everett|\n",
      "|       6|          Ottawa|\n",
      "|       1|North Sioux City|\n",
      "|       1|        Lewiston|\n",
      "|       6|          Dallas|\n",
      "|       1|     Great Falls|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*), City from {df} group by City\",df=df_address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address = spark.read.csv(\"..\\data\\Address.csv\",header=True)\n",
    "df_customer = spark.read.csv(\"..\\data\\Customer.csv\",header=True)\n",
    "df_customer_address = spark.read.csv(\"..\\data\\CustomerAddress.csv\",header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dim_customer_address = df_customer.join(df_customer_address,df_customer.CustomerID==df_customer_address.CustomerID) \\\n",
    "                                    .join(df_address,df_customer_address.AddressID==df_address.AddressID)\n",
    "df_dim_customer_address.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|Address_Count|   StateProvince|\n",
      "+-------------+----------------+\n",
      "|            9|            Utah|\n",
      "|            1|        Manitoba|\n",
      "|            1|       Brunswick|\n",
      "|            7|       Minnesota|\n",
      "|           17|          Oregon|\n",
      "|           37|           Texas|\n",
      "|           13|         Alberta|\n",
      "|            7|          Nevada|\n",
      "|           48|      Washington|\n",
      "|           14|        Illinois|\n",
      "|            3|      New Mexico|\n",
      "|           11|        Missouri|\n",
      "|           51|         Ontario|\n",
      "|            3|         Montana|\n",
      "|           16|        Michigan|\n",
      "|           17|British Columbia|\n",
      "|            4|         Wyoming|\n",
      "|           24|          Quebec|\n",
      "|           13|         Arizona|\n",
      "|           38|         England|\n",
      "+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as Address_Count, StateProvince from {df} group by StateProvince\",df=df_dim_customer_address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data = [\n",
    "    {'id': 1, 'name': 'Bob', 'department': 'Marketing', 'salary': 9104,\n",
    "     'hire_date': '2018-12-29', 'ssn': '848-97-2099', 'performance_score': 3.6,\n",
    "     'incentive_percent': 14.0, 'grade': 'D', 'grade_start_date': '2019-06-13',\n",
    "     'grade_end_date': '2021-03-05'},\n",
    "\n",
    "    {'id': 1, 'name': 'Bob', 'department': 'Marketing', 'salary': 9104,\n",
    "     'hire_date': '2018-12-29', 'ssn': '848-97-2099', 'performance_score': 3.6,\n",
    "     'incentive_percent': 14.0, 'grade': 'C', 'grade_start_date': '2019-03-28',\n",
    "     'grade_end_date': '2020-08-12'},\n",
    "\n",
    "    {'id': 2, 'name': 'Eve', 'department': 'HR', 'salary': 11405,\n",
    "     'hire_date': '2019-09-16', 'ssn': '374-89-8340', 'performance_score': 4.8,\n",
    "     'incentive_percent': None, 'grade': 'C', 'grade_start_date': '2019-11-23',\n",
    "     'grade_end_date': '2021-02-13'},\n",
    "\n",
    "    {'id': 3, 'name': 'Grace', 'department': 'Finance', 'salary': 8176,\n",
    "     'hire_date': '2017-01-03', 'ssn': '850-34-8593', 'performance_score': 4.8,\n",
    "     'incentive_percent': 15.1, 'grade': 'C', 'grade_start_date': '2017-05-29',\n",
    "     'grade_end_date': '2019-04-12'},\n",
    "\n",
    "    {'id': 4, 'name': 'Charlie', 'department': 'Marketing', 'salary': 5543,\n",
    "     'hire_date': '2017-12-28', 'ssn': '471-89-7669', 'performance_score': 3.4,\n",
    "     'incentive_percent': None, 'grade': 'C', 'grade_start_date': '2018-04-12',\n",
    "     'grade_end_date': '2020-02-21'},\n",
    "\n",
    "    {'id': 5, 'name': 'Grace', 'department': 'IT', 'salary': 11013,\n",
    "     'hire_date': '2015-07-03', 'ssn': '950-10-4559', 'performance_score': None,\n",
    "     'incentive_percent': 11.9, 'grade': 'D', 'grade_start_date': '2015-12-17',\n",
    "     'grade_end_date': '2017-09-15'},\n",
    "\n",
    "    {'id': 6, 'name': 'Eve', 'department': 'HR', 'salary': 7755,\n",
    "     'hire_date': '2016-07-18', 'ssn': '653-29-5109', 'performance_score': None,\n",
    "     'incentive_percent': 5.7, 'grade': 'A', 'grade_start_date': '2016-09-24',\n",
    "     'grade_end_date': '2018-07-01'},\n",
    "\n",
    "    {'id': 7, 'name': 'Bob', 'department': 'Sales', 'salary': 10888,\n",
    "     'hire_date': '2016-06-16', 'ssn': '549-14-5445', 'performance_score': 3.9,\n",
    "     'incentive_percent': 14.3, 'grade': 'A', 'grade_start_date': '2016-08-04',\n",
    "     'grade_end_date': '2017-11-17'},\n",
    "\n",
    "    {'id': 8, 'name': 'Alice', 'department': 'Finance', 'salary': 11532,\n",
    "     'hire_date': '2015-02-01', 'ssn': '428-18-3432', 'performance_score': None,\n",
    "     'incentive_percent': 19.0, 'grade': 'B', 'grade_start_date': '2015-07-27',\n",
    "     'grade_end_date': '2017-02-17'},\n",
    "\n",
    "    {'id': 9, 'name': 'Alice', 'department': 'Marketing', 'salary': 11169,\n",
    "     'hire_date': '2018-02-28', 'ssn': '621-46-2389', 'performance_score': None,\n",
    "     'incentive_percent': 11.8, 'grade': 'B', 'grade_start_date': '2018-06-26',\n",
    "     'grade_end_date': '2019-08-22'},\n",
    "\n",
    "    {'id': 10, 'name': 'Eve', 'department': 'Marketing', 'salary': 10591,\n",
    "     'hire_date': '2017-12-15', 'ssn': '710-34-8871', 'performance_score': None,\n",
    "     'incentive_percent': 7.1, 'grade': 'B', 'grade_start_date': '2018-05-21',\n",
    "     'grade_end_date': '2019-07-19'},\n",
    "\n",
    "    {'id': 11, 'name': 'Grace', 'department': 'Sales', 'salary': 7566,\n",
    "     'hire_date': '2019-11-24', 'ssn': '685-73-7275', 'performance_score': None,\n",
    "     'incentive_percent': None, 'grade': 'D', 'grade_start_date': '2020-01-10',\n",
    "     'grade_end_date': '2020-09-20'},\n",
    "\n",
    "    {'id': 12, 'name': 'Eve', 'department': 'IT', 'salary': 4874,\n",
    "     'hire_date': '2016-02-16', 'ssn': '602-70-5971', 'performance_score': None,\n",
    "     'incentive_percent': None, 'grade': 'B', 'grade_start_date': '2016-04-22',\n",
    "     'grade_end_date': '2017-01-13'},\n",
    "\n",
    "    {'id': 13, 'name': 'Bob', 'department': 'Finance', 'salary': 6067,\n",
    "     'hire_date': '2015-02-18', 'ssn': '965-10-2064', 'performance_score': 2.8,\n",
    "     'incentive_percent': 8.7, 'grade': 'E', 'grade_start_date': '2015-04-08',\n",
    "     'grade_end_date': '2015-10-06'},\n",
    "\n",
    "    {'id': 14, 'name': 'Eve', 'department': 'IT', 'salary': 10012,\n",
    "     'hire_date': '2015-11-24', 'ssn': '479-14-9198', 'performance_score': None,\n",
    "     'incentive_percent': 11.8, 'grade': 'E', 'grade_start_date': '2016-05-07',\n",
    "     'grade_end_date': '2017-01-08'}\n",
    "]\n",
    "column_names = [\n",
    "    \"id\", \"name\", \"department\", \"salary\", \"hire_date\", \"ssn\", \n",
    "    \"performance_score\", \"incentive_percent\", \"grade\", \n",
    "    \"grade_start_date\", \"grade_end_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(employee_data).select(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "|id |name   |department|salary|hire_date |ssn        |performance_score|incentive_percent|grade|grade_start_date|grade_end_date|\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "|1  |Bob    |Marketing |9104  |2018-12-29|848-97-2099|3.6              |14.0             |D    |2019-06-13      |2021-03-05    |\n",
      "|1  |Bob    |Marketing |9104  |2018-12-29|848-97-2099|3.6              |14.0             |C    |2019-03-28      |2020-08-12    |\n",
      "|2  |Eve    |HR        |11405 |2019-09-16|374-89-8340|4.8              |NULL             |C    |2019-11-23      |2021-02-13    |\n",
      "|3  |Grace  |Finance   |8176  |2017-01-03|850-34-8593|4.8              |15.1             |C    |2017-05-29      |2019-04-12    |\n",
      "|4  |Charlie|Marketing |5543  |2017-12-28|471-89-7669|3.4              |NULL             |C    |2018-04-12      |2020-02-21    |\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.withColumn(\"incentive_percent\",coalesce(col(\"incentive_percent\"),lit(\"5.0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "| id|   name|department|salary| hire_date|        ssn|performance_score|incentive_percent|grade|grade_start_date|grade_end_date|\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "|  1|    Bob| Marketing|  9104|2018-12-29|848-97-2099|              3.6|             14.0|    D|      2019-06-13|    2021-03-05|\n",
      "|  1|    Bob| Marketing|  9104|2018-12-29|848-97-2099|              3.6|             14.0|    C|      2019-03-28|    2020-08-12|\n",
      "|  2|    Eve|        HR| 11405|2019-09-16|374-89-8340|              4.8|              5.0|    C|      2019-11-23|    2021-02-13|\n",
      "|  3|  Grace|   Finance|  8176|2017-01-03|850-34-8593|              4.8|             15.1|    C|      2017-05-29|    2019-04-12|\n",
      "|  4|Charlie| Marketing|  5543|2017-12-28|471-89-7669|              3.4|              5.0|    C|      2018-04-12|    2020-02-21|\n",
      "|  5|  Grace|        IT| 11013|2015-07-03|950-10-4559|             NULL|             11.9|    D|      2015-12-17|    2017-09-15|\n",
      "|  6|    Eve|        HR|  7755|2016-07-18|653-29-5109|             NULL|              5.7|    A|      2016-09-24|    2018-07-01|\n",
      "|  7|    Bob|     Sales| 10888|2016-06-16|549-14-5445|              3.9|             14.3|    A|      2016-08-04|    2017-11-17|\n",
      "|  8|  Alice|   Finance| 11532|2015-02-01|428-18-3432|             NULL|             19.0|    B|      2015-07-27|    2017-02-17|\n",
      "|  9|  Alice| Marketing| 11169|2018-02-28|621-46-2389|             NULL|             11.8|    B|      2018-06-26|    2019-08-22|\n",
      "| 10|    Eve| Marketing| 10591|2017-12-15|710-34-8871|             NULL|              7.1|    B|      2018-05-21|    2019-07-19|\n",
      "| 11|  Grace|     Sales|  7566|2019-11-24|685-73-7275|             NULL|              5.0|    D|      2020-01-10|    2020-09-20|\n",
      "| 12|    Eve|        IT|  4874|2016-02-16|602-70-5971|             NULL|              5.0|    B|      2016-04-22|    2017-01-13|\n",
      "| 13|    Bob|   Finance|  6067|2015-02-18|965-10-2064|              2.8|              8.7|    E|      2015-04-08|    2015-10-06|\n",
      "| 14|    Eve|        IT| 10012|2015-11-24|479-14-9198|             NULL|             11.8|    E|      2016-05-07|    2017-01-08|\n",
      "+---+-------+----------+------+----------+-----------+-----------------+-----------------+-----+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8986.6\n"
     ]
    }
   ],
   "source": [
    "avg_salary = df_clean.selectExpr(\"avg(salary)\").first()[0]\n",
    "print(avg_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.json(\"/home/obiwan/dbverse_git/pyspark_examples/data/Azure_IR/log1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[_corrupt_record: string]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+---+-----------------------+-----------------------------------------------+\n",
      "|ID |Name      |Role    |Age|Description            |Profile_JSON                                   |\n",
      "+---+----------+--------+---+-----------------------+-----------------------------------------------+\n",
      "|1  |John Doe  |Engineer|30 |This is a string column|{\"Name\":\"John Doe\",\"Role\":\"Engineer\",\"Age\":30} |\n",
      "|2  |Jane Smith|Analyst |28 |This is a string column|{\"Name\":\"Jane Smith\",\"Role\":\"Analyst\",\"Age\":28}|\n",
      "+---+----------+--------+---+-----------------------+-----------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Role: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Profile_JSON: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Role\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Description\", StringType(), True)  # String column\n",
    "])\n",
    "\n",
    "# Hardcoded Data\n",
    "data = [\n",
    "    (1, \"John Doe\", \"Engineer\", 30, \"This is a string column\"),\n",
    "    (2, \"Jane Smith\", \"Analyst\", 28, \"This is a string column\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Convert the StructType column to JSON format\n",
    "df_with_json = df.withColumn(\n",
    "    \"Profile_JSON\", to_json(struct(\"Name\", \"Role\", \"Age\"))\n",
    ")\n",
    "\n",
    "# Show DataFrame\n",
    "df_with_json.show(truncate=False)\n",
    "\n",
    "# Print Schema\n",
    "df_with_json.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| ID|        Profile_JSON|\n",
      "+---+--------------------+\n",
      "|  1|{\"Name\":\"John Doe...|\n",
      "|  2|{\"Name\":\"Jane Smi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parsed = df_with_json.select(\"ID\",\"Profile_JSON\")\n",
    "df_parsed.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+-----------+\n",
      "|ID |Profile_Name|Profile_Role|Profile_Age|\n",
      "+---+------------+------------+-----------+\n",
      "|1  |John Doe    |Engineer    |30         |\n",
      "|2  |Jane Smith  |Analyst     |28         |\n",
      "+---+------------+------------+-----------+\n",
      "\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Profile_Name: string (nullable = true)\n",
      " |-- Profile_Role: string (nullable = true)\n",
      " |-- Profile_Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_sample = df_parsed.select(\"Profile_JSON\").limit(1).collect()[0][\"Profile_JSON\"]\n",
    "json_keys = list(json.loads(json_sample).keys())\n",
    "\n",
    "df_flattened = df_parsed.select(\"ID\", json_tuple(col(\"Profile_JSON\"), *json_keys))\n",
    "\n",
    "# Rename columns dynamically\n",
    "for old_name, new_name in zip(df_flattened.columns[1:], json_keys):\n",
    "    df_flattened = df_flattened.withColumnRenamed(old_name, f\"Profile_{new_name}\")\n",
    "\n",
    "# Show final result\n",
    "df_flattened.show(truncate=False)\n",
    "\n",
    "# Print schema\n",
    "df_flattened.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
